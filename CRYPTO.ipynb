{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crytocurrency Price prediction\n",
    "\n",
    "This notebook predicts the price of a target cryptocurrency given a few features about it. We use time-series data to predict the next price. As time-series data has an inherent order to it, using a recurrent architecture benefits us. This notebook uses LSTMs to do so.\n",
    "\n",
    "Lets start with some imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SEQLEN = 60\n",
    "FUTURE_PREDICT = 3\n",
    "RATIO = \"LTC-USD\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell has also defined a few variables...\n",
    "\n",
    "1. **SEQLEN** : the length of the sequences that are generated and fed to the model.\n",
    "\n",
    "2. **FUTURE_PREDICT** : the amount of values to predict in the future.\n",
    "\n",
    "3. **RATIO** : the ratio (or cryptocurrency) that has to be predicted.\n",
    "\n",
    "These variables are frequently used and hence given a proper variable.\n",
    "\n",
    "\n",
    "The next step is to form a dataframe from the CSVs...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD_close</th>\n",
       "      <th>vol_BTC-USD</th>\n",
       "      <th>LTC-USD_close</th>\n",
       "      <th>vol_LTC-USD</th>\n",
       "      <th>ETH-USD_close</th>\n",
       "      <th>vol_ETH-USD</th>\n",
       "      <th>BCH-USD_close</th>\n",
       "      <th>vol_BCH-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1528968660</th>\n",
       "      <td>6489.549805</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>96.580002</td>\n",
       "      <td>9.647200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>871.719971</td>\n",
       "      <td>5.675361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968720</th>\n",
       "      <td>6487.379883</td>\n",
       "      <td>7.706374</td>\n",
       "      <td>96.660004</td>\n",
       "      <td>314.387024</td>\n",
       "      <td>486.01001</td>\n",
       "      <td>26.019083</td>\n",
       "      <td>870.859985</td>\n",
       "      <td>26.856577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968780</th>\n",
       "      <td>6479.410156</td>\n",
       "      <td>3.088252</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>77.129799</td>\n",
       "      <td>486.00000</td>\n",
       "      <td>8.449400</td>\n",
       "      <td>870.099976</td>\n",
       "      <td>1.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968840</th>\n",
       "      <td>6479.410156</td>\n",
       "      <td>1.404100</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>7.216067</td>\n",
       "      <td>485.75000</td>\n",
       "      <td>26.994646</td>\n",
       "      <td>870.789978</td>\n",
       "      <td>1.749862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968900</th>\n",
       "      <td>6479.979980</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>96.389999</td>\n",
       "      <td>524.539978</td>\n",
       "      <td>486.00000</td>\n",
       "      <td>77.355759</td>\n",
       "      <td>870.000000</td>\n",
       "      <td>1.680500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BTC-USD_close  vol_BTC-USD  LTC-USD_close  vol_LTC-USD  \\\n",
       "time                                                                 \n",
       "1528968660    6489.549805     0.587100      96.580002     9.647200   \n",
       "1528968720    6487.379883     7.706374      96.660004   314.387024   \n",
       "1528968780    6479.410156     3.088252      96.570000    77.129799   \n",
       "1528968840    6479.410156     1.404100      96.500000     7.216067   \n",
       "1528968900    6479.979980     0.753000      96.389999   524.539978   \n",
       "\n",
       "            ETH-USD_close  vol_ETH-USD  BCH-USD_close  vol_BCH-USD  \n",
       "time                                                                \n",
       "1528968660            NaN          NaN     871.719971     5.675361  \n",
       "1528968720      486.01001    26.019083     870.859985    26.856577  \n",
       "1528968780      486.00000     8.449400     870.099976     1.124300  \n",
       "1528968840      485.75000    26.994646     870.789978     1.749862  \n",
       "1528968900      486.00000    77.355759     870.000000     1.680500  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create an empty dataframe...\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# We will be reading all the CSVs present...so we create a list of all cryptocurrencies present...\n",
    "ratios=[\"BTC-USD\",\"LTC-USD\",\"ETH-USD\",\"BCH-USD\"]\n",
    "\n",
    "# and then pass them into reading one-by-one...\n",
    "for ratio in ratios:\n",
    "    \n",
    "    #Read the file...\n",
    "    dataset=f\"D:\\\\PROJECTS\\\\Datasets\\\\crypto_data\\\\{ratio}.csv\"\n",
    "    df = pd.read_csv(dataset,names=[\"time\",\"low\",\"high\",\"open\",\"close\",\"volume\"])\n",
    "    \n",
    "    \n",
    "    #rename the columns to put all cryptos in one df...\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"vol_{ratio}\"},inplace=True)\n",
    "    \n",
    "    #set the index of the dataframe as the timestamp...\n",
    "    df.set_index(\"time\",inplace=True)\n",
    "    \n",
    "    #finally, remove all columns except the closing price(our target variable) \n",
    "    # and the traaded volume which is the quantity of that currency being traded...\n",
    "    df = df[[f\"{ratio}_close\", f\"vol_{ratio}\"]]\n",
    "    \n",
    "    #if we are reading the first file, assign it to main_df\n",
    "    # otherwise, append the df to main_df...\n",
    "    if len(main_df)==0:\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df=main_df.join(df)\n",
    "\n",
    "# Lets preview our dataframe...\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little background on the data\n",
    "\n",
    "As we can see, we have the closing prices and volumes of 4 cryptocurrencies. We will be predicting LiteCoin's price\n",
    "Traded as (LTC-USD). Here, LTC-USD is a ratio which is how many USDs can be bought for a unit LTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function classifies if the movement was upwards or downwards \n",
    "# (bullish or bearish for the commerce folks out there!)\n",
    "# Here, 1 specifies bullish movement\n",
    "# and 0 specifies bearish movement...\n",
    "\n",
    "def classify(currPrice,futPrice):\n",
    "    if float(futPrice) > float(currPrice):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a target value for each data row\n",
    "\n",
    "Now that we have our dataframe loaded, we need to find our target variable. However, in such scenarios, the input variables next instance is our target variable (the future price of a coin at \"t\" is the current price of the coin at time \"t+1\"). We thereby create target values for each datarow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future\n",
      "time                                \n",
      "1528968660      96.580002  96.500000\n",
      "1528968720      96.660004  96.389999\n",
      "1528968780      96.570000  96.519997\n",
      "1528968840      96.500000  96.440002\n",
      "1528968900      96.389999  96.470001\n"
     ]
    }
   ],
   "source": [
    "# Create columns with the name \"future\" that will have the future price...\n",
    "# for a price at time \"t\", and leap of \"n\"\n",
    "# df[t,'future'] has value referring to price at time (t+n)\n",
    "\n",
    "\n",
    "main_df['future'] = main_df[f\"{RATIO}_close\"].shift(-FUTURE_PREDICT)\n",
    "print(main_df[[f\"{RATIO}_close\",\"future\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we map all our input and outputs to the classification function \n",
    "# to find if the movement was upwards or downwards...\n",
    "\n",
    "main_df[\"target\"] = list(map(classify,main_df[f\"{RATIO}_close\"],main_df[\"future\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future  target\n",
      "time                                        \n",
      "1528968660      96.580002  96.500000       0\n",
      "1528968720      96.660004  96.389999       0\n",
      "1528968780      96.570000  96.519997       0\n",
      "1528968840      96.500000  96.440002       0\n",
      "1528968900      96.389999  96.470001       1\n",
      "1528968960      96.519997  96.400002       0\n",
      "1528969020      96.440002  96.400002       0\n",
      "1528969080      96.470001  96.400002       0\n",
      "1528969140      96.400002  96.400002       0\n",
      "1528969200      96.400002  96.400002       0\n"
     ]
    }
   ],
   "source": [
    "print(main_df[[f\"{RATIO}_close\",\"future\",\"target\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(main_df.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534922100\n"
     ]
    }
   ],
   "source": [
    "# Defining a split index to split the data into training and validation sets...\n",
    "last_5pct = times[-int(0.05*len(times))]\n",
    "print(last_5pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training and validation sets...\n",
    "\n",
    "val_main_df = main_df[(main_df.index >= last_5pct)]\n",
    "main_df = main_df[(main_df.index < last_5pct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we will be using a double ended queue\n",
    "# Find more here : https://docs.python.org/2/library/collections.html\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "\n",
    "def preprocessDf(df):\n",
    "    # drop the column \"future\"...\n",
    "    df = df.drop(\"future\",1)\n",
    "    \n",
    "    # calculate the percent change in input variables\n",
    "    # Remove any NaNs generated in the process...\n",
    "    # use scikit to scale the values in [0,1]...\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col != \"target\":\n",
    "            df[col] = df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "    \n",
    "    \n",
    "    #Again, just to be sure...\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Create a sequence to be passed to the model...\n",
    "    # A sequence is a list of inputs in a defined order...\n",
    "    seq_data=[]\n",
    "    prev_days = deque(maxlen=SEQLEN)\n",
    "    \n",
    "    \n",
    "    # df.values returns all data in numpy array without the headers...\n",
    "    # [TODO] : Shift it to df.to_numpy()\n",
    "    \n",
    "    # We iterate in it and create a list of prices of previous days(the length being SEQLEN).\n",
    "    # Once a \"sequence\" of such data is ready, we put it on the seq_data.\n",
    "    # So, seq_data is a list of sequences, each of which is in order.\n",
    "    # the inner sequence is thereby preserved.\n",
    "    # We do shuffle the list of seq_data...\n",
    "    \n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days) == SEQLEN:\n",
    "            seq_data.append([np.array(prev_days),i[-1]])\n",
    "    random.shuffle(seq_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Should we buy or should we sell?\n",
    "    buys=[]\n",
    "    sells=[]\n",
    "    \n",
    "    \n",
    "    # find out buys and sells through our target variable...\n",
    "    for seq,target in seq_data:\n",
    "        if target==0:\n",
    "            sells.append([seq,target])\n",
    "        elif target==1:\n",
    "            buys.append([seq,target])\n",
    "     \n",
    "    #shuffle everything again...\n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    # Create equal sets of data... \n",
    "    lwr = min(len(buys),len(sells))\n",
    "    buys = buys[:lwr]\n",
    "    sells = sells[:lwr]\n",
    "    \n",
    "    \n",
    "    seq_data = buys + sells\n",
    "    random.shuffle(seq_data)\n",
    "    \n",
    "\n",
    "    X=[]\n",
    "    y=[]\n",
    "    \n",
    "    # Create X (inputs) and y (outputs) for the given data...\n",
    "    for seq,target in seq_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    \n",
    "    # finally, return numpy arrays of X and y...\n",
    "    return np.array(X),y\n",
    "\n",
    "\n",
    "# Pass the dataframes to obtain the data...\n",
    "xTrain,yTrain = preprocessDf(main_df)\n",
    "xTest,yTest = preprocessDf(val_main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69188, 60, 8)\n",
      "(3062, 60, 8)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape)\n",
    "print(xTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model\n",
    "\n",
    "We will now create a model that takes our data as input and spits out either a buy or sell action. To do this, we take advantage of inherent order in our data(the time) to extract more information. This can be done easily by RNNs or LSTMs which take previous output into consideration as well... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\envML\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\envML\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 69188 samples, validate on 3062 samples\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\envML\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "69188/69188 [==============================] - 36s 520us/sample - loss: 0.7132 - acc: 0.5088 - val_loss: 0.6932 - val_acc: 0.4987\n",
      "Epoch 2/10\n",
      "69188/69188 [==============================] - 33s 474us/sample - loss: 0.6939 - acc: 0.5178 - val_loss: 0.7138 - val_acc: 0.5007\n",
      "Epoch 3/10\n",
      "69188/69188 [==============================] - 33s 477us/sample - loss: 0.6868 - acc: 0.5505 - val_loss: 0.6821 - val_acc: 0.5745\n",
      "Epoch 4/10\n",
      "69188/69188 [==============================] - 35s 512us/sample - loss: 0.6842 - acc: 0.5597 - val_loss: 0.6785 - val_acc: 0.5673\n",
      "Epoch 5/10\n",
      "69188/69188 [==============================] - 34s 498us/sample - loss: 0.6819 - acc: 0.5633 - val_loss: 0.6754 - val_acc: 0.5627\n",
      "Epoch 6/10\n",
      "69188/69188 [==============================] - 36s 519us/sample - loss: 0.6828 - acc: 0.5620 - val_loss: 0.6869 - val_acc: 0.5408\n",
      "Epoch 7/10\n",
      "69188/69188 [==============================] - 35s 503us/sample - loss: 0.6807 - acc: 0.5675 - val_loss: 0.6729 - val_acc: 0.5787\n",
      "Epoch 8/10\n",
      "69188/69188 [==============================] - 34s 495us/sample - loss: 0.6782 - acc: 0.5717 - val_loss: 0.6779 - val_acc: 0.5699\n",
      "Epoch 9/10\n",
      "69188/69188 [==============================] - 34s 498us/sample - loss: 0.6767 - acc: 0.5751 - val_loss: 0.6759 - val_acc: 0.5751\n",
      "Epoch 10/10\n",
      "69188/69188 [==============================] - 35s 503us/sample - loss: 0.6750 - acc: 0.5800 - val_loss: 0.6750 - val_acc: 0.5794\n"
     ]
    }
   ],
   "source": [
    "#used to define filenames and save models...\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "#used to define the actual model...\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dropout,CuDNNLSTM,Dense,BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "\n",
    "\n",
    "EPOCHS=10\n",
    "BATCH=64\n",
    "NAME=f\"{SEQLEN}-Day-{RATIO}-Predictor-{int(time.time())}\"\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Layer 1 : LSTM-dropout-bathcnorm\n",
    "model.add(CuDNNLSTM(128,input_shape=(xTrain.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Layer 2 : LSTM-dropout-batchnorm\n",
    "model.add(CuDNNLSTM(128,input_shape=(xTrain.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Layer 3 : LSTM-dropout-batchnorm\n",
    "model.add(CuDNNLSTM(128,input_shape=(xTrain.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Layer 4 : LSTM-dropout-batchnorm\n",
    "model.add(CuDNNLSTM(128,input_shape=(xTrain.shape[1:])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Layer 5 : Fully connected layer with dropout\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Layer 6 : Final outer layer to classify as buy/sell...\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "# Use Adam optimiser on sparse categoricalentropy loss(BCE will work as well) \n",
    "# and print out the accuracy of the model...\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3,decay=1e-6),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#defining a few callbacks to monitor the model...\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{NAME}\")\n",
    "\n",
    "#checkpointing the model to save the best validation accuracy weights...\n",
    "FILEPATH = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"\n",
    "chkpt = ModelCheckpoint(\"models/{}.model\".format(FILEPATH,monitor=\"val_acc\",verbose=1,save_best_only=True,mode=\"max\"))\n",
    "\n",
    "\n",
    "#train the model...\n",
    "history = model.fit(xTrain,yTrain,batch_size = BATCH, epochs=EPOCHS,\n",
    "                    validation_data=(xTest,yTest),\n",
    "                    callbacks=[tensorboard,chkpt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envML",
   "language": "python",
   "name": "envml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
